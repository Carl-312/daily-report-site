# API å‚è€ƒæ–‡æ¡£

æœ¬æ–‡æ¡£æè¿° Daily Report Site å„æ¨¡å—çš„æ¥å£å®šä¹‰å’Œä½¿ç”¨æ–¹æ³•ã€‚

---

## ğŸ“¡ æ–°é—»æºæ¥å£ (sources/)

### é€šç”¨æ¥å£è§„èŒƒ

æ‰€æœ‰æ–°é—»æºæ¨¡å—å¿…é¡»å®ç°ä»¥ä¸‹æ¥å£:

```python
def fetch() -> List[Dict[str, str]]:
    """
    ä»æ–°é—»æºè·å–æ–‡ç« åˆ—è¡¨
    
    Returns:
        æ–‡ç« åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡ç« åŒ…å«ä»¥ä¸‹å­—æ®µ:
        [
            {
                "title": str,   # æ–‡ç« æ ‡é¢˜ (å¿…éœ€)
                "link": str,    # å®Œæ•´ URL (å¿…éœ€)
                "desc": str     # ç®€çŸ­æè¿°ï¼Œ50-200 å­— (å¿…éœ€)
            },
            ...
        ]
    
    Raises:
        requests.RequestException: ç½‘ç»œè¯·æ±‚å¤±è´¥
        ValueError: æ•°æ®æ ¼å¼é”™è¯¯
    """
```

### å½“å‰å®ç°çš„æº

#### AIBase (`sources/aibase.py`)

**æè¿°**: ä¸­æ–‡ AI èµ„è®¯èšåˆå¹³å°

**ç«¯ç‚¹**: `https://www.aibase.com`

**ç‰¹ç‚¹**:
- è¿”å›ä¸­æ–‡æ ‡é¢˜å’Œæè¿°
- è‡ªåŠ¨è¿‡æ»¤å¹¿å‘Šå†…å®¹
- é»˜è®¤è·å–æœ€æ–° 20 ç¯‡æ–‡ç« 

**ç¤ºä¾‹è¾“å‡º**:
```python
[
    {
        "title": "OpenAI å‘å¸ƒ GPT-5 é¢„è§ˆç‰ˆ",
        "link": "https://www.aibase.com/zh/news/12345",
        "desc": "OpenAI ä»Šæ—¥å®£å¸ƒæ¨å‡º GPT-5 é¢„è§ˆç‰ˆï¼Œæ€§èƒ½æå‡ 50%..."
    }
]
```

#### TechCrunch (`sources/techcrunch.py`)

**æè¿°**: å›½é™…ç§‘æŠ€æ–°é—»åª’ä½“

**ç«¯ç‚¹**: `https://techcrunch.com`

**ç‰¹ç‚¹**:
- è‹±æ–‡å†…å®¹
- åŒ…å«åˆ›æŠ•ã€AIã€ç¡¬ä»¶ç­‰å¤šä¸ªç±»åˆ«
- RSS Feed æŠ“å–

**ç¤ºä¾‹è¾“å‡º**:
```python
[
    {
        "title": "Startup X raises $50M Series B",
        "link": "https://techcrunch.com/2026/01/21/startup-x-...",
        "desc": "Startup X, a leading AI platform, announced today..."
    }
]
```

#### The Verge (`sources/theverge.py`)

**æè¿°**: ç§‘æŠ€ä¸æ–‡åŒ–æ–°é—»

**ç«¯ç‚¹**: `https://www.theverge.com`

**ç‰¹ç‚¹**:
- è‹±æ–‡å†…å®¹
- ç§‘æŠ€ã€æ¸¸æˆã€æ–‡åŒ–ç­‰ä¸»é¢˜
- HTML è§£æ

---

## ğŸ¤– æ‘˜è¦ç”Ÿæˆæ¥å£ (summarizer.py)

### summarize()

```python
def summarize(
    articles: List[Dict[str, str]], 
    stream: bool = False
) -> str:
    """
    ä½¿ç”¨ LLM API ç”Ÿæˆæ™ºèƒ½æ‘˜è¦
    
    Args:
        articles: æ–‡ç« åˆ—è¡¨ (æ¥è‡ª sources)
        stream: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º (å®æ—¶æ‰“å°)
    
    Returns:
        Markdown æ ¼å¼çš„æ‘˜è¦å†…å®¹
    
    Raises:
        ConnectionError: API è¿æ¥å¤±è´¥
        AuthenticationError: API Key æ— æ•ˆ
        
    Environment:
        MODELSCOPE_API_KEY: ModelScope API å¯†é’¥ (å¿…éœ€)
        MODELSCOPE_MODEL: æ¨¡å‹åç§° (å¯é€‰ï¼Œé»˜è®¤ ZhipuAI/GLM-5)
    """
```

**è°ƒç”¨ç¤ºä¾‹**:
```python
from summarizer import summarize

articles = [
    {"title": "...", "link": "...", "desc": "..."},
    # ...
]

content = summarize(articles, stream=True)
print(content)
```

**API è¯·æ±‚æ ¼å¼**:
```json
{
  "model": "ZhipuAI/GLM-5",
  "messages": [
    {
      "role": "system",
      "content": "<prompts/daily.md çš„å†…å®¹>"
    },
    {
      "role": "user",
      "content": "[{\"title\": \"...\", \"link\": \"...\"}, ...]"
    }
  ],
  "stream": true,
  "temperature": 0.7
}
```

**API å“åº”æ ¼å¼** (stream=true):
```
data: {"choices": [{"delta": {"content": "## ä»Šæ—¥è¦é—»\n\n"}}]}
data: {"choices": [{"delta": {"content": "### OpenAI å‘å¸ƒ..."}}]}
...
data: [DONE]
```

### offline_summary()

```python
def offline_summary(articles: List[Dict[str, str]]) -> str:
    """
    æœ¬åœ°æ‘˜è¦ç®—æ³• (æ— éœ€ API)
    
    Args:
        articles: æ–‡ç« åˆ—è¡¨
    
    Returns:
        Markdown æ ¼å¼çš„ç®€å•åˆ—è¡¨
    
    Note:
        æ­¤æ–¹æ³•ä»…æ ¼å¼åŒ–åŸå§‹å†…å®¹ï¼Œä¸è¿›è¡Œæ™ºèƒ½æ‘˜è¦
    """
```

**è¾“å‡ºç¤ºä¾‹**:
```markdown
## ğŸ“° ä»Šæ—¥èµ„è®¯

### [OpenAI å‘å¸ƒ GPT-5](https://...)
OpenAI ä»Šæ—¥å®£å¸ƒæ¨å‡º GPT-5 é¢„è§ˆç‰ˆ...

### [Startup X èèµ„ 5000 ä¸‡ç¾å…ƒ](https://...)
Startup X, a leading AI platform...
```

### test_connection()

```python
def test_connection() -> bool:
    """
    æµ‹è¯• ModelScope API è¿æ¥
    
    Returns:
        True: è¿æ¥æˆåŠŸ
        False: è¿æ¥å¤±è´¥
    
    Prints:
        è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯
    """
```

**ä½¿ç”¨åœºæ™¯**:
```bash
# CLI
python main.py test

# ä»£ç 
from summarizer import test_connection
if test_connection():
    print("API é…ç½®æ­£ç¡®")
```

---

## ğŸ”§ å·¥å…·å‡½æ•° (utils/)

### dedupe()

```python
from utils import dedupe

def dedupe(articles: List[Article]) -> List[Article]:
    """
    åŸºäº URL å’Œæ ‡é¢˜çš„å»é‡
    
    Args:
        articles: Article å¯¹è±¡åˆ—è¡¨
    
    Returns:
        å»é‡åçš„åˆ—è¡¨
    
    Algorithm:
        1. URL ç²¾ç¡®åŒ¹é…
        2. æ ‡é¢˜ Levenshtein è·ç¦» < 5 è§†ä¸ºé‡å¤
        3. ä¿ç•™æœ€æ—©å‡ºç°çš„æ–‡ç« 
    """
```

### today_ymd() / today_cn()

```python
from utils import today_ymd, today_cn

today_ymd()  # "2026-01-21"
today_cn()   # "1æœˆ21æ—¥"
```

### save_json() / load_json()

```python
from utils import save_json, load_json

# ä¿å­˜
path = save_json(
    directory="data",
    filename="2026-01-21",
    data={"articles": [...]},
)
# ç”Ÿæˆ: data/2026-01-21.json

# åŠ è½½
data = load_json("data", "2026-01-21")
```

### save_markdown()

```python
from utils import save_markdown

path = save_markdown(
    directory="content",
    filename="2026-01-21",
    content="# Title\n\nContent...",
)
# ç”Ÿæˆ: content/2026-01-21.md
```

---

## ğŸ—ï¸ é™æ€ç«™ç‚¹æ„å»º (build.py)

### build_site()

```python
from build import build_site

def build_site() -> None:
    """
    æ„å»ºå®Œæ•´çš„é™æ€ç«™ç‚¹
    
    Process:
        1. æ‰«æ content/*.md
        2. ä¸ºæ¯ç¯‡æ–‡ç« ç”Ÿæˆç‹¬ç«‹ HTML
        3. ç”Ÿæˆé¦–é¡µ index.html
        4. ç”Ÿæˆå½’æ¡£é¡µ archive.html
        5. å¤åˆ¶é™æ€èµ„æº (CSS)
    
    Output:
        docs/
        â”œâ”€â”€ index.html
        â”œâ”€â”€ archive.html
        â”œâ”€â”€ 2026-01-21.html
        â”œâ”€â”€ 2026-01-20.html
        â””â”€â”€ style.css
    """
```

### parse_frontmatter()

```python
def parse_frontmatter(content: str) -> Tuple[Dict, str]:
    """
    è§£æ Markdown Frontmatter (å¯é€‰åŠŸèƒ½)
    
    Args:
        content: Markdown æ–‡ä»¶å†…å®¹
    
    Returns:
        (metadata, body)
    
    Example:
        Input:
            ---
            title: Custom Title
            ---
            # Content
        
        Output:
            ({"title": "Custom Title"}, "# Content")
    """
```

---

## ğŸ“ é…ç½®ç®¡ç† (config.py)

### get_config()

```python
from config import get_config

cfg = get_config()

# è®¿é—®é…ç½®
print(cfg.api_key)       # ä» .env è¯»å–
print(cfg.sources)       # ä» config.yaml è¯»å–
print(cfg.max_articles)  # 14
```

### Config æ•°æ®ç±»

```python
@dataclass
class Config:
    # API é…ç½®
    api_key: str
    model: str
    
    # æ–°é—»æºé…ç½®
    sources: Dict[str, bool]
    max_articles: int
    
    # Syft é…ç½® (å¯é€‰)
    syft_web_app_url: Optional[str]
    syft_secret_key: Optional[str]
    
    # è·¯å¾„é…ç½®
    data_dir: Path
    content_dir: Path
    docs_dir: Path
    
    # æ‘˜è¦é…ç½®
    prompt_path: Path
    prefer_chinese: bool
    title_max: int
    desc_max: int
```

---

## ğŸ”Œ æ‰©å±•ç¤ºä¾‹

### æ·»åŠ è‡ªå®šä¹‰æ–°é—»æº

```python
# sources/hacker_news.py
import requests
from typing import List, Dict

def fetch() -> List[Dict[str, str]]:
    """ä» Hacker News è·å–å¤´æ¡"""
    response = requests.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()[:10]
    
    articles = []
    for story_id in story_ids:
        story_resp = requests.get(
            f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
        )
        story = story_resp.json()
        
        articles.append({
            "title": story["title"],
            "link": story.get("url", f"https://news.ycombinator.com/item?id={story_id}"),
            "desc": story.get("text", "No description available")[:200],
        })
    
    return articles
```

**æ³¨å†Œ**:
```python
# sources/__init__.py
from .hacker_news import fetch as fetch_hackernews

SOURCE_REGISTRY = {
    # ...
    "hackernews": fetch_hackernews,
}
```

**å¯ç”¨**:
```yaml
# config.yaml
sources:
  hackernews: true
```

---

**Last Updated**: 2026-01-21  
**Version**: 1.0.0
